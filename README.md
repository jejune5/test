# ai-notes

一个用于记录AI笔记的仓库。

---

## 1. cv

---

## 2. nlp
### 2.1 nlp综合
- [【导航】NLP资源综合导航@fighting41love/funNLP](https://github.com/fighting41love/funNLP)
- [【面试】NLP面试笔记（仅问题）@km1994/NLP-Interview-Notes](https://github.com/km1994/NLP-Interview-Notes)
- [【面试】AIGC-interview@315386775/DeepLearing-Interview-Awesome-2024](https://github.com/315386775/DeepLearing-Interview-Awesome-2024)
- [【面试】那些你不知道的事@km1994/nlp_paper_study](https://github.com/km1994/nlp_paper_study)
- [【面试】LLM面试含答案-问题基于km1994/NLP-Interview-Notes@jackaduma/awesome_LLMs_interview_notes](https://github.com/jackaduma/awesome_LLMs_interview_notes)
- [【竞赛】NLP任务竞赛汇总@TingFree/NLPer-Arsenal](https://github.com/TingFree/NLPer-Arsenal)

### 2.2 LLMs系列
- [【数据】-医疗训练数据@onejune2018/Awesome-Medical-Healthcare-Dataset-For-LLM](https://github.com/onejune2018/Awesome-Medical-Healthcare-Dataset-For-LLM)
- [【模型】-【Grok-1】314B模型@xai-org/grok-1](https://github.com/xai-org/grok-1)
- [【模型】-国产大模型列表@wgwang/awesome-LLMs-In-China](https://github.com/wgwang/awesome-LLMs-In-China)
- [【模型】-Yi-6B/34B 可以到200k @01-ai/Yi](https://github.com/01-ai/Yi)
- [【模型】-已发布的中文LLMs列表@HqWu-HITCS/Awesome-Chinese-LLM](https://github.com/HqWu-HITCS/Awesome-Chinese-LLM)
- [【模型】-LLaMA-开源的LLaMA模型@facebookresearch/llama](https://github.com/facebookresearch/llama)
- [【模型】-LLaMA中文-@ymcui/Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)
- [【模型】-LLaMA2中文-@ymcui/Chinese-LLaMA-Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2)
- [【模型】-OpenLLaMA中文-@FittenTech/OpenLLaMA-Chinese](https://github.com/FittenTech/OpenLLaMA-Chinese)
- [【模型】-ChatGLM3-@THUDM/ChatGLM3](https://github.com/THUDM/ChatGLM3)
- [【模型】-【Llama-Chinese】中文LLAMA@Llama-Chinese](https://github.com/LlamaFamily/Llama-Chinese)
- [【训练】-【unsloth】-微调LLaMA3速度快](https://github.com/unslothai/unsloth)
- [【训练】-【LLaMA-Factory】-微调训练框架@hiyouga/LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)
- [【训练】-【Firefly】-流萤LLMs训练代码@yangjianxin1/Firefly](https://github.com/yangjianxin1/Firefly)
- [【训练】-【swift】-qwen官方训练框架@modelscope/swift](https://github.com/modelscope/swift)
- [【训练】-【PEFT】-PLMs参数精调方法@huggingface/peft](https://github.com/huggingface/peft)
- [【训练】-【ChatGLM-Finetuning】-ChatGLM多种方式微调（Freeze、lora、pt、全参等）@liucongg/ChatGLM-Finetuning](https://github.com/liucongg/ChatGLM-Finetuning)
- [【训练】-【MedicalGPT】-医疗GPT训练框架@shibing624/MedicalGPT](https://github.com/shibing624/MedicalGPT)
- [【推理】-【LLaMA.cpp】-LLaMA的C++推理代码@ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp)
- [【推理】-【chatglm.cpp】@li-plus/chatglm.cpp](https://github.com/li-plus/chatglm.cpp)
- [【推理】-【fastllm】-基于cpp的推理框架，可实现移动端@ztxz16/fastllm](https://github.com/ztxz16/fastllm)
- [【推理】-【vllm】-vllm推理@vllm-project/vllm](https://github.com/vllm-project/vllm)
- [【推理】-【lmdeploy】-介绍说比vLLM快@InternLM/lmdeploy](https://github.com/InternLM/lmdeploy)
- [【推理】-【FastChat】-支持vllm加速、openaiapi和webui@lm-sys/FastChat](https://github.com/lm-sys/FastChat)
- [【推理】-【flash-attention】flash-attention推理加速@Dao-AILab/flash-attention](https://github.com/Dao-AILab/flash-attention)
- [【评测】-评测资源列表@onejune2018/Awesome-LLM-Eval](https://github.com/onejune2018/Awesome-LLM-Eval)
- [【评测】-LLMSurvey-大语言模型综述](https://github.com/RUCAIBox/LLMSurvey)
- [【评测】-【opencompass】-大模型评测榜单](https://github.com/open-compass/opencompass)
- [【Prompt】-【LangGPT】- 角色扮演提示词模板@EmbraceAGI/LangGPT](https://github.com/EmbraceAGI/LangGPT)
- [【Prompt】-【GPTs】- 提示词模板@linexjlin/GPTs](https://github.com/linexjlin/GPTs)
- [【RAG】-【Langchain-Chatchat】@chatchat-space/Langchain-Chatchat](https://github.com/chatchat-space/Langchain-Chatchat)
- [【RAG】-【组件索引列表】@frutik/Awesome-RAG](https://github.com/frutik/Awesome-RAG)
- [【Agent】-【Graph_Toolformer】-图数据+LLM+API_call构造Agent@jwzhanggy/Graph_Toolformer](https://github.com/jwzhanggy/Graph_Toolformer)
- [【Agent】-AutoGPT-实现GPT的自动化操作@Significant-Gravitas/Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT)
- [【Agent】-【XAgent】-面壁智能XAgent@OpenBMB/XAgent](https://github.com/OpenBMB/XAgent)
- [【Agent】-【modelscope-agent】-阿里agent@modelscope/modelscope-agent](https://github.com/modelscope/modelscope-agent)
- [【Agent】-【Qwen-agent】-阿里agent@QwenLM/Qwen-Agent](https://github.com/QwenLM/Qwen-Agent)
- [【工具】-【Json】-【super-json-mode】大模型抽取信息的json格式@varunshenoy/super-json-mode](https://github.com/varunshenoy/super-json-mode)
- [【工具】-【ChatALL】-大模型多合一@sunner/ChatALL](https://github.com/sunner/ChatALL)
- [【工具】-【chatgpt】-镜像网站@LiLittleCat/awesome-free-chatgpt](https://github.com/LiLittleCat/awesome-free-chatgpt)
- [【工具】-【gpt4free】-免费的GPT-4逆向接口@xtekky/gpt4free](https://github.com/xtekky/gpt4free)
- [【工具】-【openai格式API】- openai api@xusenlinzy/api-for-open-llm](https://github.com/xusenlinzy/api-for-open-llm)
- [【应用】-【GPT-Tools】-将多个GPT可以接入聊天软件等，py实现@zhayujie/bot-on-anything](https://github.com/zhayujie/bot-on-anything)
- [~~【工具】-[BingChat]-Bing Chat for All Browsers，可以让chrome等浏览器使用的BingChat的插件@anaclumos/bing-chat-for-all-browsers~~](https://github.com/anaclumos/bing-chat-for-all-browsers)

### 2.3 向量模型-Embedding
- [【工具】-【open-text-embeddings】-仿openai API格式的embeddingAPI@limcheekin/open-text-embeddings](https://github.com/limcheekin/open-text-embeddings)

### 2.4 文本分类-Text Classification
- [文本分类工具，LR，Xgboost，TextCNN，FastText，TextRNN，BERT等分类模型实现，开箱即用。@shibing624/pytextclassifier](https://github.com/shibing624/pytextclassifier)
- [[FastText]@facebookresearch/fastText](https://github.com/facebookresearch/fastText.git)


### 2.5 信息抽取-Information Extraction
- [UIE-torch@HUSTAI/uie_pytorch](https://github.com/HUSTAI/uie_pytorch)

### 2.6 文本摘要-Text Summary
- [【TextRank4ZH】中文文本摘要@letiantian/TextRank4ZH](https://github.com/letiantian/TextRank4ZH)

### 2.7 对话系统
- [【对话系统】-基于大模型的多轮对话、填槽、反问@answerlink/IntelliQ](https://github.com/answerlink/IntelliQ)
- [【对话系统】-基于Bert的意图-槽位识别@Linear95/bert-intent-slot-detector](https://github.com/Linear95/bert-intent-slot-detector)
- [【对话系统】-业界一些对话系统资料(2022)](https://github.com/lizhe2004/chatbot-list)


---

## 3. audio
### 3.1 ASR
- [[MMS]-Scaling Speech Technology to 1000+ languages多语种ASR@facebookresearch/fairseq](https://github.com/facebookresearch/fairseq/blob/main/examples/mms/README.md)
- [[Whisper]-@openai/whisper](https://github.com/openai/whisper)
- [[whisper.cpp]whisper cpp实现-@ggerganov/whisper.cpp](https://github.com/ggerganov/whisper.cpp)
- [[FunASR]-阿里达摩院端到端ASR@alibaba-damo-academy/FunASR](https://github.com/alibaba-damo-academy/FunASR)
- [[WeNet]-端到端ASR@wenet-e2e/wenet](https://github.com/wenet-e2e/wenet)

### 3.2 TTS
- [一个TTS工具整合框架@coqui-ai/TTS](https://github.com/coqui-ai/TTS)
- [[VITS]-对抗学习的条件变分自编码器@jaywalnut310/vits](https://github.com/jaywalnut310/vits)
- [[VITS]-论文代码解读视频@B站/deep_thoughts](https://www.bilibili.com/video/BV1wU4y1q7po/?spm_id_from=333.999.0.0)
- [[VITS-fast-fine-tuning]-快速微调框架@Plachtaa/VITS-fast-fine-tuning](https://github.com/Plachtaa/VITS-fast-fine-tuning)

### 3.3 VC
- [[so-vits-svc]-声音克隆变声器，可实现AI孙燕姿@svc-develop-team/so-vits-svc](https://github.com/svc-develop-team/so-vits-svc)
- [[RVC]-一个基于VITS的简单易用的语音转换（变声器）框架@RVC-Project/Retrieval-based-Voice-Conversion-WebUI](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI)

### 3.4 vad
- [[pyannote]-声音活动检测(speaker diarization)@pyannote/pyannote-audio](https://github.com/pyannote/pyannote-audio)
- [[说话人分离-contentvec]-说话人分离@auspicious3000/contentvec](https://github.com/auspicious3000/contentvec/)

### 3.5 音频处理

- [[demucs]-伴奏、乐器、人声分离@facebookresearch/demucs](https://github.com/facebookresearch/demucs)
- [[uv]-伴奏与人声分离工具GUI版@Anjok07/ultimatevocalremovergui](https://github.com/Anjok07/ultimatevocalremovergui)
- [[HuBert]-预训练模型-音频特征提取器@facebookresearch/av_hubert](https://github.com/facebookresearch/av_hubert)

---

## 4. dev-tools
- [[向量数据库-faiss]-支持GPU的向量数据库-@facebookresearch/faiss](https://github.com/facebookresearch/faiss)
- [[向量数据库-hnswlib]-py封装c++实现的快速近邻搜索算法@nmslib/hnswlib](https://github.com/nmslib/hnswlib)
- [[部署-torch2trt]-将torch模型转为TensorRT模型的工具，由TensorRT Python API构建@NVIDIA-AI-IOT/torch2trt](https://github.com/NVIDIA-AI-IOT/torch2trt)
- [[部署-netron]-查看onnx模型结构@lutzroeder/netron](https://github.com/lutzroeder/netron)
- [[部署-onnx-simplifier]-onnx模型结构简化@daquexian/onnx-simplifier](https://github.com/daquexian/onnx-simplifier)
- [[文本、图像、音频标注工具-doccano]@doccano/doccano](https://github.com/doccano/doccano)
- 
